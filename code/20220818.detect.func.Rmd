---
title: "test_IERpackage"
author: "4621509 桐原巧"
date: "7/7/2022"
output: html_document
---

```{r}
library(dplyr)
library(readr)
library(tidyverse)
library(careless)
```



### 検知のための各関数を記述
- ロングストリング関数(パッケージと同一)
- 各ブロックごとのロングストリングを出すべき
```{r}
longstring <- function(x, avg=FALSE,split=FALSE,q.length) {
  #何分割するか
  num.split <- length(q.length)
  # subfunction that calculates the length of consecutive identical responses
  rle_string_long <- function(x) {
    rle_list <- rle(x) #lengthが長さでvalueが実際の値
    longstr <- max(rle_list$lengths)
    #avgstr <- mean(rle_list$lengths)
    return(longstr)
  }
  rle_string_avg <- function(x) {
    rle_list <- rle(x) #lengthが長さでvalueが実際の値
    avgstr <- mean(rle_list$lengths)
    return(avgstr)
  }
  
  #必要な問題の長さを1から順番にベクトルとして返す関数
  rep.func <- function(q.length){
    i=1
    vec=c()
    while(i<length(q.length)+1){
    vec <- append(vec,rep(i,q.length[i]))
    #print(i,q.length$count[i])
    i=i+1
    }
    return(vec)
  }
  # apply the subfunctions to each row (case, subject)
  #output <- apply(x, 1, rle_string)
  #output <- data.frame(t(output))
  #colnames(output) <- (c('longstr','avgstr'))

  #if(avg == TRUE) {
  #  return(output)
  #} else {
  #  return(output[,'longstr'])
  #}
  
  
  #アレンジ部分
  out <-  apply(x, 1, rle_string_long)
  out <- data.frame(out)
  if(split == TRUE) {
    chunk <- function(x) split(x, rep.func(q.length))#111222333のように同じ番号の列でデータを分割
    split_x <- apply(x, 1, chunk)#データフレームを分割してリストに
    out_split <- t(replicate(nrow(x), rep(NA, num.split)))
    colnames(out_split) <- paste0("lsa",1:num.split)
    for(k in 1:nrow(out_split)) {
      split_x_single <- split_x[[k]]
			#リストに対してそれぞれのブロックでの最長の回答の長さを出してリストを外している
			#行に対して追加していく
      out_split[k,] <- unlist(lapply(split_x_single, rle_string_long))
    }
      out_split <- data.frame(out, out_split)
      colnames(out_split)[1] <- "lsatotal"
      return(out_split)} else { #split subsection end
      return(out)
      }
}
```

```{r}
longstring(use.data1,split=T,q.length)
careless_dataset <- careless_dataset
careless::longstring(careless_dataset)
```


- IRV関数
-- 問題ごとの項目数が違う場合にも対応できるように改良
```{r}
irv <- function(x, na.rm = TRUE, split = FALSE,q.length) {
  num.split <- length(q.length)
  #必要な問題の長さを1から順番にベクトルとして返す関数
  rep.func <- function(q.length){
    i=1
    vec=c()
    while(i<num.split+1){
    vec <- append(vec,rep(i,q.length[i]))
    #print(i,q.length$count[i])
    i=i+1
    }
    return(vec)
  }
  out <- apply(x, 1, stats::sd, na.rm = na.rm)
  
  if(split == TRUE) {
    chunk <- function(x,n) split(x, rep.func(q.length))
    split_x <- apply(x, 1, chunk, num.split)
    out_split <- t(replicate(nrow(x), rep(NA, num.split)))
    colnames(out_split) <- paste0("irv",1:num.split)
    for(k in 1:nrow(out_split)) {
      split_x_single <- split_x[[k]]
			#リストに対してそれぞれのブロックでの標準偏差を出してリストを外している
			#行に対して追加していく
      out_split[k,] <- unlist(lapply(split_x_single, stats::sd, na.rm = na.rm), use.names = FALSE)
    }
      out_split <- data.frame(out, out_split)
      colnames(out_split)[1] <- "irvTotal"
      return(out_split)} else { #split subsection end
      return(out)
    }
}
```

-マハラノビス距離
```{r}
mahad <- function(x, plot = TRUE, flag = FALSE, confidence = 0.99, na.rm = TRUE) {
  if(na.rm == FALSE) {
    if(any(is.na(x)) == TRUE) {stop("Some values are NA. Mahalanobis distance was not computed.
                                      Use na.rm = TRUE to use available cases.", call. = FALSE)}
    }
  #remove rows with all NA and issue warning
  complete.na <- apply(x, 1, function(y) { all(is.na(y)) } )
  if(any(complete.na)) {
    warning("Some cases contain only NA values. The Mahalanobis distance will be calculated using available cases.",
            call. = FALSE) }
	#NAがある行が削除され、残ったデータフレーム
  x_filtered <- x[!complete.na,]

  maha_data <- as.numeric(psych::outlier(x_filtered, plot, bad = 0, na.rm = na.rm))
  d_sq <- rep_len(NA, nrow(x_filtered))#NAを人数分用意するベクトル
  d_sq[!complete.na] <- maha_data#TRUEであるベクトルだけにマハラビノス距離を入れる
	
	#外れ値にはフラグをつける
  if(flag == TRUE) {
    cut <- stats::qchisq(confidence, ncol(x))#分位点関数　　累積確率密度と自由度を入力
    flagged <- (d_sq > cut)
    return(data.frame(d_sq = d_sq, flagged = flagged))
  }
  else{ return(d_sq) }
}
```

- 偶奇一貫性
-- factorsにはq.lengthを入れると項目数を指定できる
```{r}
evenodd <- function(x, factors, diag = FALSE) {
  #initialize a result dataset
  warning("Computation of even-odd has changed for consistency of interpretation
          with other indices. This change occurred in version 1.2.0. A higher
          score now indicates a greater likelihood of careless responding. If
          you have previously written code to cut score based on the output of
          this function, you should revise that code accordingly.")

  if(length(factors) == 1) {
    stop("You have called even-odd with only a single factor. \n The even-odd method requires multiple factors to work correctly.",
            call. = FALSE) }
  if(sum(factors) > ncol(x)) {
    stop("The number of items specified by 'factors' exceeds the number of columns in 'x'.",
            call. = FALSE) }
  if(sum(factors) != ncol(x)) {
    warning("The number of items specified by 'factors' does not match the number of columns in 'x'. \n Please check if this is what you want.",
            call. = FALSE) }

  # initalize empty list for persons holding the persons even scores and odd scores
  eo_vals <- vector("list", nrow(x))

  # Loop through each Person
  for(i in 1:nrow(x)) {
    # Initialize an object to hold the factor e/o means for the current person
    f <- matrix(rep(NA, 2*length(factors)), length(factors), ncol=2)
    start <- 1

    # loop through each factor
    for(j in 1:length(factors)) {
      if(j>1) start <- start + (factors[j-1])
      end <- (factors[j]-1) + start#j=1の場合はendはfactors[1]まで
													　　　　　 #j=2の場合はendはfactors[1]からfactors[1]+factors[2]まで

      # Subset x with items for the current factor
      s <- x[i,start:end]#一人のある項目に対する回答列
      ind <- seq(1:length(colnames(s)))
      e_ind <- which(ind %% 2 == 0)#偶数番号の問題番号のベクトル　
      o_ind <- which(ind %% 2 == 1)
      f[j,1] <- mean(t(s[e_ind]), na.rm = TRUE)#ある人のある項目の偶数番号の回答平均
      f[j,2] <- mean(t(s[o_ind]), na.rm = TRUE)#ある人のある項目の奇数番号の回答平均
    }
    # assign the even and odd values to eo_vals
    eo_vals[[i]] <- f#リストに項目数*2(偶数、奇数)の行列が人数分入る
  }


  #calculate number of even/odd pairs for which no comparison can be computed because of NAs
  eo_missing <- lapply(eo_vals, function(i) sum(!is.na(apply(i, 1, sum))))

  # scan for persons for which no even-odd can be calculated when all values are same, leading to
  # a correlation of NA because there is no variance/standard deviation.
  eo_sdzero <-  lapply(eo_vals, function(i) apply(i, 2, stats::sd))#列に対する標準偏差　各人の各項目に対する奇数番号と偶数番号の回答列の平均の標準偏差
  eo_sdzero <- sapply(eo_sdzero, function(i) any(i == 0, na.rm = TRUE))
  if(any(eo_sdzero, na.rm = TRUE)) warning("One or more observations have zero variance in even and/or odd values. \nThis results in NA values for these observations.\nIncluding more factors may alleviate this issue.",
                             call. = FALSE)

  # Calculate within-person correlation between even and odd sub-scales
  # then apply the Spearman-Brown correction for split-half reliability
  # and store the result in the output vector.
  eo_cor <- sapply(eo_vals, function(f) {#sapplyはベクトルで返す
    # suppressWarnings for standard deviation 0 which happens when each value-pairs is same
    val <- suppressWarnings(stats::cor(f[, 1], f[, 2], use = "pairwise.complete.obs"))
    val <- (2 * val) / (1 + val) #split-half
    if (!is.na(val) && val < -1) val <- -1
    return(val)
  })

  # transform eo  such that higher scores are indicating carelessness
  eo_cor = 0 - eo_cor

  if(diag == FALSE) {return(eo_cor)}
  else {return(data.frame(eo_cor, eo_missing))}
}
```

- 心理的同義語と対義語
- defaltで0.6以上の相関を持っていることを仮定
```{r}
psychsyn <- function(x, critval=.60, anto=FALSE, diag=FALSE, resample_na=TRUE) {
  x <- as.matrix(x)
  item_pairs <- get_item_pairs(x, critval, anto)
  
  synonyms <- apply(x,1,syn_for_one, item_pairs, resample_na)
  synonyms_df <- as.data.frame(aperm(synonyms))
  colnames(synonyms_df) <- c("numPairs", "cor")
  
  if(diag==TRUE) { return(synonyms_df) }
  else { return(synonyms_df$cor) }
}

# Helper function that identifies psychometric synonyms in a given dataset
get_item_pairs <- function(x, critval=.60, anto=FALSE) {
  critval <- abs(critval) #Dummy Proofing
  
  correlations <- stats::cor(x, use = "pairwise.complete.obs")#共分散行列
  correlations[upper.tri(correlations, diag=TRUE)] <- NA #対角線を含めた上三角行列で上側がTRUEとなりそこをNAとする
  correlations <- as.data.frame(as.table(correlations)) #テーブル型にしてデータ型にする var1 va2 Freqという列ができる

  # Identifying item pairs differs depending on whether the user wants
  # Psychometric Synonyms or Psychometric Antonyms
  if(anto==FALSE) {
    item_pair_names <- correlations[which(correlations$Freq > critval, arr.ind=TRUE),c(1,2)]#var1とvar2の組み合わせを出力
    if(nrow(item_pair_names)==0) {
      stop("No Psychometric Synonyms found.")
    }
  }
  else if(anto==TRUE) {
    item_pair_names <- correlations[which(correlations$Freq < -critval, arr.ind=TRUE),c(1,2)]
    if(nrow(item_pair_names)==0) {
      stop("No Psychometric Antonyms found.")
    }
  }

  matches <- item_pair_names
  return(matches)#var1とvar2のデータフレームが返される 相関が0.6以上の列名のペア
}

# Helper function to calculate the within person correlation for a single individual
syn_for_one <- function(x, item_pairs, resample_na) {#一人に対する演算
  item_pairs_omit_na <- which(!(is.na(x[item_pairs[,1]]) | is.na(x[item_pairs[,2]])))#whichでペアの列にNAがないインデックス番号をベクトルで返す
  sum_item_pairs <- length(item_pairs_omit_na)
  #only execute if more than two item pairs
  if(sum_item_pairs > 2) {
		#ある人に対する問題ペアの列ができる
    itemvalues <- cbind(as.numeric(x[as.numeric(item_pairs[,1])]), as.numeric(x[as.numeric(item_pairs[,2])]))#列の名前を列の番号に変換

    # helper that calculates within-person correlation
    psychsyn_cor <- function(x) {
      suppressWarnings(stats::cor(x, use = "pairwise.complete.obs", method = "pearson")[1,2])
    }

    # if resample_na == TRUE, re-calculate psychsyn should a result return NA
    if(resample_na == TRUE) {
      counter <- 1
      synvalue <- psychsyn_cor(itemvalues)
      while(counter <= 10 & is.na(synvalue)) {
        itemvalues <- t(apply(itemvalues, 1, sample, 2, replace = F))
        synvalue <- psychsyn_cor(itemvalues)
        counter = counter+1
      }
    } else {
      synvalue <- psychsyn_cor(itemvalues) # executes if resample_na == FALSE
      }

  } else {synvalue <- NA} # executes if insufficient item pairs

  return(c(sum_item_pairs, synvalue))
}
```

- person total correlation
-- 抽出したデータ全体のperson total correlation
```{r}
ptc <- function(data,use.colname,split=FALSE){
num.split <- length(use.colname)
#データに対してptcの値を人数分出す関数　出力はベクトル
  ptc_func <- function(data){
    cm <- as.vector(colMeans(data))#列の平均ベクトル
    ptc <- apply(data,1,function(x){suppressWarnings(cor(as.vector(as.matrix(x)),cm))})
    return(ptc)
  }

#必要な問題の長さを1から順番にベクトルとして返す関数
  rep.func <- function(q.length){
    i=1
    vec=c()
    while(i<length(q.length)+1){
    vec <- append(vec,rep(i,q.length[i]))
    #print(i,q.length$count[i])
    i=i+1
  }
  return(vec)
  }
  
#アレンジ部分
out <- ptc_func(data)#全谷たいするptc
out <- data.frame(out)
  if(split == TRUE) {
    #chunk <- function(x) split(x,rep.func(q.length))#111222333のように同じ番号の列でデータを分割
    #split_x <- apply(x, 1, chunk)#データフレームを分割してリストに
    out_split <- t(replicate(nrow(data), rep(NA, num.split)))
    colnames(out_split) <- paste0("ptc",1:num.split)
    for(k in 1:length(use.colname)) {
      split_x_data <- data %>% select(starts_with(use.colname[k]))
      #split_x_single <- split_x[[k]]
			#リストに対してそれぞれのブロックでの最長の回答の長さを出してリストを外している
			#行に対して追加していく
      out_split[,k] <- ptc_func(split_x_data)
    }
    out_split <- data.frame(out, out_split)
    colnames(out_split)[1] <- "ptctotal"
    return(out_split)} else { #split subsection end
    return(out)
  }
}



```


###処理を記述した関数
use.data：使用するデータからnullを削除したもの
cal.q.length：ブロックごとの項目数を順番に返す関数
```{r}
#入力：使う番号の名前
#出力：使うデータフレーム
use.data <- function(v,data=jacsis2020){
  name.vec <- factor(v,levels = v)
  usedata <- data %>% select(starts_with(as.vector(name.vec))) %>% na.omit()
}

#入力：使う番号の名前
#出力：項目数のベクトル
cal.q.length <- function(v,colnamedata=colname.data){
  name.vec <- factor(v,levels = v)
  q.length <- colnamedata %>% filter(colname %in% name.vec) %>% arrange(colname)
  return(q.length$count)
}

```

### 全体に共通する変数の記述
固定された変数
- jacsis2020：jacsis2020の生データ
- jacsis_ipw：アンケート回答者に対する重み
- colname.start3：項目の頭3文字が入ったベクトル
- colname.data：どの問題が何項目を含んでいるかのデータ

シナリオによって変化する変数
- use.colname：使う項目を指定するベクトル　
- ues.data1：必要なデータフレーム
- q.length：使うデータの問題ごとの項目数ベクトル
```{r}
jacsis2020 <- read_csv("../data/ローデータ_1of1.csv",locale=locale(encoding="CP932"),skip = 1)
jacsis_ipw <- read_csv("../data/JACSIS20IPW20201020.csv",locale=locale(encoding="CP932"))

#項目に対して何問の問題があるか
colname.start3 <- colnames(jacsis2020) %>% str_sub(start = 1,end=3) 

colname.data <- data.frame(ID=c(1:length(colname.start3)),colname=colname.start3) %>%
group_by(colname) %>% 
summarise(count=n() , .groups="drop") %>% 
arrange(desc(count))


use.colname=c("Q22","Q23","Q24","Q25")

use.data1 <- use.data(use.colname)

q.length <- cal.q.length(use.colname)
```


#関数の使用例
```{r}
#任意の列番号を選んでそのデータを返す
#q_numはベクトル
long.result <- longstring(use.data1,avg=F,split=T,q.length)
irv.result <- irv(use.data1,na.rm = TRUE, split = T,q.length)
mahad.result <- mahad(use.data1, plot = TRUE, flag = TRUE, confidence = 0.99, na.rm = TRUE)
#evenodd.result <- evenodd(use.data1, q.length, diag = TRUE)

psychsyn.result <- psychsyn(use.data1, critval=.60, anto=FALSE, diag=FALSE, resample_na=TRUE)

psychant.result <- psychsyn(use.data1, critval=-.60, anto=TRUE, diag=FALSE, resample_na=TRUE)

ptc.result <- ptc(use.data1,use.colname,split=TRUE)


    
    
cal_func <- function(x,q.length){
  long.result <- longstring(x,avg=F)
  irv.result <- irv(x,na.rm = TRUE, split = FALSE, q.length)
  mahad.result <- mahad(x, plot = TRUE, flag = FALSE, confidence = 0.99, na.rm = TRUE)
  #evenodd.result <- evenodd(x, factors, diag = FALSE)
  psychsyn.result <- psychsyn(x, critval=.60, anto=FALSE, diag=FALSE, resample_na=TRUE)
  psychant.result <- psychsyn(x, critval=-.60, anto=TRUE, diag=FALSE, resample_na=TRUE)
  ptc.result <- ptc(x)
  
}



```

### データ作り
```{r}
#入力　問題数　項目数　リッカー尺度
# 項目に対する分布のパラメータ
# 矛盾回答の生成方法　ランダムな人を選び　文字列を生成

```

